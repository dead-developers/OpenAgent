# OpenAgent configuration for Ollama

[llm.ollama]
model = "llama2"                      # Default model, you can change this to any model you have in Ollama
base_url = "http://localhost:11434"   # Default Ollama API endpoint
api_key = ""                          # Not needed for Ollama
max_tokens = 4096                     # Maximum number of tokens in the response
temperature = 0.7                     # Controls randomness
api_type = "ollama"                   # Specify API type as ollama
api_version = ""                      # Not needed for Ollama
